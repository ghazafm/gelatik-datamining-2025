{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.flame import FlameFOV\n",
    "from dataset.flame import FlameThermal\n",
    "from dataset.flame import FlameRGB\n",
    "from dataset.flame import FlameSatelite\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.ops import box_convert\n",
    "import torchvision.ops as ops\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from helper.image_processing import SquarePadTransform\n",
    "from helper.utils import collate_fn\n",
    "from helper.modelling import generate_proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose = transforms.Compose(\n",
    "    [\n",
    "        # SquarePadTransform(),\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FlameSatelite(download=True, transform=compose)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    collate_fn=collate_fn,  # Use custom collate function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the DataLoader\n",
    "# for images, bboxes in train_loader:\n",
    "#     print(\"Image batch shape:\", images.shape)\n",
    "#     print(\"Bounding box batch shape:\", bboxes.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, bbox = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"savefig.bbox\"] = \"tight\"\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_xyxy = box_convert(bbox[11], in_fmt=\"cxcywh\", out_fmt=\"xyxy\")\n",
    "\n",
    "result = draw_bounding_boxes(image[11], bbox_xyxy, colors=\"blue\", width=5)\n",
    "show(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomBackbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomBackbone, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),  # Input: [B, 3, H, W]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                 # Downsample\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_layers(x)  # Output: Feature maps\n",
    "    \n",
    "class RPN(nn.Module):\n",
    "    def __init__(self, in_channels, num_anchors):\n",
    "        super(RPN, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.cls_layer = nn.Conv2d(256, num_anchors, kernel_size=1)  # Object vs Background\n",
    "        self.reg_layer = nn.Conv2d(256, num_anchors * 4, kernel_size=1)  # Bounding box regression\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        cls_logits = self.cls_layer(x)  # Shape: [B, num_anchors, H, W]\n",
    "        reg_logits = self.reg_layer(x)  # Shape: [B, num_anchors * 4, H, W]\n",
    "        return cls_logits, reg_logits\n",
    "\n",
    "class ROIPooling(nn.Module):\n",
    "    def __init__(self, output_size):\n",
    "        super(ROIPooling, self).__init__()\n",
    "        self.roi_pool = ops.roi_pool\n",
    "\n",
    "    def forward(self, features, proposals):\n",
    "        # proposals: List of [x_min, y_min, x_max, y_max] for each image\n",
    "        return self.roi_pool(features, proposals, output_size=(7, 7))  # Adjust output size as needed\n",
    "    \n",
    "class DetectionHead(nn.Module):\n",
    "    def __init__(self, in_features, num_classes=2):  # 2 for background and fire\n",
    "        super(DetectionHead, self).__init__()\n",
    "        self.flatten = nn.Flatten() \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.cls_layer = nn.Linear(1024, num_classes)  # Class probabilities (background vs fire)\n",
    "        self.reg_layer = nn.Linear(1024, num_classes * 4)  # Bounding box offsets\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        class_logits = self.cls_layer(x)\n",
    "        bbox_offsets = self.reg_layer(x)\n",
    "        return class_logits, bbox_offsets\n",
    "\n",
    "\n",
    "class DetectionLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DetectionLoss, self).__init__()\n",
    "        self.cls_loss = nn.CrossEntropyLoss()\n",
    "        self.reg_loss = nn.SmoothL1Loss()\n",
    "\n",
    "    def forward(self, cls_preds, reg_preds, cls_targets, reg_targets):\n",
    "        loss_cls = self.cls_loss(cls_preds, cls_targets)\n",
    "        \n",
    "        # Compute regression loss (only if targets are available)\n",
    "        if reg_targets.numel() > 0:\n",
    "            reg_preds = reg_preds[:, :4]  # Single-class regression\n",
    "            loss_reg = self.reg_loss(reg_preds, reg_targets)\n",
    "        else:\n",
    "            loss_reg = torch.tensor(0.0, device=cls_preds.device)\n",
    "\n",
    "        return loss_cls + loss_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize components\n",
    "backbone = CustomBackbone()\n",
    "rpn = RPN(in_channels=64, num_anchors=9)  # Match with output of backbone\n",
    "roi_pool = ROIPooling(output_size=(7, 7))\n",
    "head = DetectionHead(in_features=64 * 7 * 7)  # Adjust for your classes\n",
    "loss_fn = DetectionLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(backbone.parameters()) + \n",
    "    list(rpn.parameters()) + \n",
    "    list(head.parameters()), lr=1e-4\n",
    ")\n",
    "\n",
    "# Training\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for idx, (images, targets) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        features = backbone(images)\n",
    "        rpn_logits, rpn_bboxes = rpn(features)\n",
    "        \n",
    "        # Generate proposals (e.g., NMS on RPN output)\n",
    "        proposals = generate_proposals(rpn_logits, rpn_bboxes)\n",
    "        # ROI pooling\n",
    "        pooled_features = roi_pool(features, proposals)\n",
    "        # Detection head\n",
    "        cls_preds, reg_preds = head(pooled_features)\n",
    "        # Create the labels for classification (cls_preds)\n",
    "        labels = torch.ones(cls_preds.shape[0], dtype=torch.long).to(images.device)  # All ones for fire\n",
    "        \n",
    "        reg_targets = torch.ones([cls_preds.shape[0],4], dtype=torch.long).to(images.device)  # All ones for fire\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(cls_preds, reg_preds, labels, reg_targets)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemastik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
